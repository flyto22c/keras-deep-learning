{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\u00272.0.8\u0027"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import keras\n",
        "keras.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "将文本分解成的单元叫做标记\n",
        "文本分解成标记的过程叫做分词\n",
        "两种方法：对标记做one-hot编码；使用词嵌入"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 示例：单词级的one-hot编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "{\u0027The\u0027: 1,\n \u0027cat\u0027: 2,\n \u0027sat\u0027: 3,\n \u0027on\u0027: 4,\n \u0027the\u0027: 5,\n \u0027mat.\u0027: 6,\n \u0027dog\u0027: 7,\n \u0027ate\u0027: 8,\n \u0027my\u0027: 9,\n \u0027homework.\u0027: 10}"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 5
        },
        {
          "data": {
            "text/plain": "(2, 10, 11)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 5
        },
        {
          "data": {
            "text/plain": "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n\n       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np          \n",
        "samples \u003d [\u0027The cat sat on the mat.\u0027, \u0027The dog ate my homework.\u0027]\n",
        "token_index \u003d {}            # 构建标记的索引 { \u0027word\u0027: 1 }\n",
        "for sample in samples:\n",
        "    for word in sample.split():\n",
        "        if word not in token_index:\n",
        "            token_index[word] \u003d len(token_index) + 1\n",
        "token_index\n",
        "\n",
        "max_length \u003d 10            # 做one-hot编码；只考虑样本的前10个单词；索引中没有0\n",
        "results \u003d np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index \u003d token_index.get(word)\n",
        "        results[i, j, index] \u003d 1.\n",
        "results.shape\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 示例：字符级的one-hot编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "{\u00270\u0027: 1,\n \u00271\u0027: 2,\n \u00272\u0027: 3,\n \u00273\u0027: 4,\n \u00274\u0027: 5,\n \u00275\u0027: 6,\n \u00276\u0027: 7,\n \u00277\u0027: 8,\n \u00278\u0027: 9,\n \u00279\u0027: 10,\n \u0027a\u0027: 11,\n \u0027b\u0027: 12,\n \u0027c\u0027: 13,\n \u0027d\u0027: 14,\n \u0027e\u0027: 15,\n \u0027f\u0027: 16,\n \u0027g\u0027: 17,\n \u0027h\u0027: 18,\n \u0027i\u0027: 19,\n \u0027j\u0027: 20,\n \u0027k\u0027: 21,\n \u0027l\u0027: 22,\n \u0027m\u0027: 23,\n \u0027n\u0027: 24,\n \u0027o\u0027: 25,\n \u0027p\u0027: 26,\n \u0027q\u0027: 27,\n \u0027r\u0027: 28,\n \u0027s\u0027: 29,\n \u0027t\u0027: 30,\n \u0027u\u0027: 31,\n \u0027v\u0027: 32,\n \u0027w\u0027: 33,\n \u0027x\u0027: 34,\n \u0027y\u0027: 35,\n \u0027z\u0027: 36,\n \u0027A\u0027: 37,\n \u0027B\u0027: 38,\n \u0027C\u0027: 39,\n \u0027D\u0027: 40,\n \u0027E\u0027: 41,\n \u0027F\u0027: 42,\n \u0027G\u0027: 43,\n \u0027H\u0027: 44,\n \u0027I\u0027: 45,\n \u0027J\u0027: 46,\n \u0027K\u0027: 47,\n \u0027L\u0027: 48,\n \u0027M\u0027: 49,\n \u0027N\u0027: 50,\n \u0027O\u0027: 51,\n \u0027P\u0027: 52,\n \u0027Q\u0027: 53,\n \u0027R\u0027: 54,\n \u0027S\u0027: 55,\n \u0027T\u0027: 56,\n \u0027U\u0027: 57,\n \u0027V\u0027: 58,\n \u0027W\u0027: 59,\n \u0027X\u0027: 60,\n \u0027Y\u0027: 61,\n \u0027Z\u0027: 62,\n \u0027!\u0027: 63,\n \u0027\"\u0027: 64,\n \u0027#\u0027: 65,\n \u0027$\u0027: 66,\n \u0027%\u0027: 67,\n \u0027\u0026\u0027: 68,\n \"\u0027\": 69,\n \u0027(\u0027: 70,\n \u0027)\u0027: 71,\n \u0027*\u0027: 72,\n \u0027+\u0027: 73,\n \u0027,\u0027: 74,\n \u0027-\u0027: 75,\n \u0027.\u0027: 76,\n \u0027/\u0027: 77,\n \u0027:\u0027: 78,\n \u0027;\u0027: 79,\n \u0027\u003c\u0027: 80,\n \u0027\u003d\u0027: 81,\n \u0027\u003e\u0027: 82,\n \u0027?\u0027: 83,\n \u0027@\u0027: 84,\n \u0027[\u0027: 85,\n \u0027\\\\\u0027: 86,\n \u0027]\u0027: 87,\n \u0027^\u0027: 88,\n \u0027_\u0027: 89,\n \u0027`\u0027: 90,\n \u0027{\u0027: 91,\n \u0027|\u0027: 92,\n \u0027}\u0027: 93,\n \u0027~\u0027: 94,\n \u0027 \u0027: 95,\n \u0027\\t\u0027: 96,\n \u0027\\n\u0027: 97,\n \u0027\\r\u0027: 98,\n \u0027\\x0b\u0027: 99,\n \u0027\\x0c\u0027: 100}"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 8
        },
        {
          "data": {
            "text/plain": "(2, 50, 101)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 8
        },
        {
          "data": {
            "text/plain": "array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 8
        }
      ],
      "source": [
        "import string                 \n",
        "samples \u003d [\u0027The cat sat on the mat.\u0027, \u0027The dog ate my homework.\u0027]\n",
        "characters \u003d string.printable   # 所有可打印的ASCII字符 | characters\u003d\u002701234..tuv..NOPQt\\n\\x0b\\x0c\u0027\n",
        "token_index \u003d dict(zip(characters, range(1, len(characters) + 1)))\n",
        "token_index\n",
        "\n",
        "max_length \u003d 50                 # 做one-hot编码；只考虑样本的前50个字符；索引中没有0\n",
        "results \u003d np.zeros((len(samples), max_length, max(token_index.values()) + 1))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, character in enumerate(sample[:max_length]):\n",
        "        index \u003d token_index.get(character)\n",
        "        results[i, j, index] \u003d 1.\n",
        "results.shape\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# keras实现单词级onehot编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "{\u0027the\u0027: 1,\n \u0027cat\u0027: 2,\n \u0027sat\u0027: 3,\n \u0027on\u0027: 4,\n \u0027mat\u0027: 5,\n \u0027dog\u0027: 6,\n \u0027ate\u0027: 7,\n \u0027my\u0027: 8,\n \u0027homework\u0027: 9}"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 10
        },
        {
          "data": {
            "text/plain": "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 10
        },
        {
          "data": {
            "text/plain": "(2, 1000)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 10
        },
        {
          "data": {
            "text/plain": "array([[0., 1., 1., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]])"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 10
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer        \n",
        "samples \u003d [\u0027The cat sat on the mat.\u0027, \u0027The dog ate my homework.\u0027]\n",
        "tokenizer \u003d Tokenizer(num_words\u003d1000) # 只考虑前1000个最常见单词\n",
        "tokenizer.fit_on_texts(samples)       # \n",
        "\n",
        "word_index \u003d tokenizer.word_index     # 标记索引 ；下标中没有0\n",
        "word_index\n",
        "sequences \u003d tokenizer.texts_to_sequences(samples)\n",
        "sequences\n",
        "one_hot_results \u003d tokenizer.texts_to_matrix(samples, mode\u003d\u0027binary\u0027)\n",
        "one_hot_results.shape\n",
        "one_hot_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# 散列技巧单词级one-hot编码"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "(2, 10, 1000)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 12
        }
      ],
      "source": [
        "samples \u003d [\u0027The cat sat on the mat.\u0027, \u0027The dog ate my homework.\u0027]   # 将单词散列为固定长度的向量\n",
        "dimensionality \u003d 1000\n",
        "max_length \u003d 10\n",
        "results \u003d np.zeros((len(samples), max_length, dimensionality))\n",
        "for i, sample in enumerate(samples):\n",
        "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "        index \u003d abs(hash(word)) % dimensionality\n",
        "        results[i, j, index] \u003d 1.\n",
        "results.shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:learn36]",
      "language": "python",
      "name": "conda-env-learn36-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}