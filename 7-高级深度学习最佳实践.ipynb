{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras函数式API\n",
    "* 多输入模型\n",
    "* 多输出模型：适用于不同的输出具有统计相关性\n",
    "* 类图模型\n",
    "  * **Inception系列网络**：依赖于Inception模块，输入被多个并行的卷积分支处理\n",
    "  * **残差连接**：最早出现于ResNet网络，将前面的表示重新注入下游数据流中\n",
    "\n",
    "\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/07fig02.jpg)\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/HighResolutionFigures/figure_7-3.png)\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/07fig04.jpg)\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/HighResolutionFigures/figure_7-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数式API简介"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "input_tensor = Input(shape=(32,))\n",
    "dense = layers.Dense(32, activation='relu') # 每个层是一个函数\n",
    "output_tensor = dense(input_tensor)         # 张量 = 层函数（张量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\pengfeizhang\\Anaconda3\\envs\\learn36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 11.6495\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 11.5873\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 11.5753\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5698\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5653\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 11.5622\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 11.5595\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 11.5575\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 37us/step - loss: 11.5555\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 11.5535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a50cac3c88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 88us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.550111495971679"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()           # Sequentiao模型\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "seq_model.summary()\n",
    "\n",
    "input_tensor = Input(shape=(64,))  # 函数式API模型\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "api_model = Model(input_tensor, output_tensor)\n",
    "api_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_model.compile(optimizer='rmsprop', loss='categorical_crossentropy') # 编译，相同\n",
    "\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "api_model.fit(x_train, y_train, epochs=10, batch_size=128)               # 训练相同\n",
    "api_model.evaluate(x_train, y_train)                                     # 评估相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果使用不相关的输入、输出构建模型，会得到`RuntimeError`  \n",
    "这个报错告诉我们，Keras无法从给定输出张量到达`input_1`\n",
    "~~~python\n",
    ">>> unrelated_input = Input(shape=(32,))\n",
    ">>> bad_model = model = Model(unrelated_input, output_tensor)\n",
    "RuntimeError: Graph disconnected: cannot\n",
    "obtain value for tensor\n",
    "Tensor(\"input_1:0\", shape=(?, 64), dtype=float32) at layer \"input_1\".\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输入模型\n",
    "* 张量的组合方式：相加`keras.layers.add`，连接`keras.layers.concatenate`等\n",
    "* 典型的问答模型连个输入：一个自然语言描述问题；一个文本片段（提供用于回答问题的信息）。然后模型生成一个回答，最简单情况下，回答只包含一个单词，通过对预定义的词表做softmax得到。\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/HighResolutionFigures/figure_7-6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 10000)  640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           1284224     embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 16)           641088      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 48)           0           lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 500)          24500       concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,909,812\n",
      "Trainable params: 2,909,812\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model  # 一个双输入的问答模型\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "\n",
    "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None,),dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question],axis=-1)\n",
    "answer = layers.Dense(answer_vocabulary_size,activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer) # 指定连个输入和输出\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0000e+00 - acc: 0.5920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a6039000b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size,size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, 1,size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "model.fit([text, question], answers, \n",
    "          epochs=10, batch_size=128) # \n",
    "model.fit({'text': text, 'question': question}, answers,\n",
    "          epochs=10, batch_size=128) # 对输入命名之后才能这样做。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输出模型\n",
    "* 为不同的输出指定不同的损失函数，使用不同的损失加权\n",
    "* 例子中预测：年龄（标量回归）、收入（标量会不）、性别（二分类）\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/07fig07.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,activation='softmax',name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input,[age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 10.])\n",
    "model.compile(optimizer='rmsprop',                        # 使用不同的损失加权\n",
    "              loss={'age': 'mse',                         # [3,5]左右\n",
    "                    'income': 'categorical_crossentropy', # \n",
    "                    'gender': 'binary_crossentropy'},     # 0.1左右\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                  'income': income_targets,\n",
    "                  'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层组成的有向无环图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception模块\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/07fig08.jpg)\n",
    "* Inception模块：分别学习空间特征和主通道特征\n",
    "* Inception V3位于：`keras.applications.inception_v3`包括在ImageNet上预训练得到的权重\n",
    "* Xception：代表极端的Inception。空间卷积+逐点卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "branch_a = layers.Conv2D(128, 1,activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 残差连接\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/HighResolutionFigures/figure_7-5.png)\n",
    "* 解决了大规模深度学习的两个共性问题：\n",
    "  * **梯度消失（引入一个纯线性的信息携带轨道）**\n",
    "  * **表示瓶颈（弥补信息在传播过程中的丢失）**。\n",
    "* 前面的层不是和后面的层连接在一起，而是**与后面层的激活相加**\n",
    "  * 形状相同：**恒等残差连接**\n",
    "  * 形状不同：**线性残差连接**（可以是不带激活的Dense层；对于卷积特征图是不待激活的1*1卷积）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers  # 恒等残差连接\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers  # 线性残差连接\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "y = layers.add([y, residual]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享层权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32) # 将一个LSTM实例化一次，多次重复使用一个层实例\n",
    "\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型作为层\n",
    "使用**双摄像头作为输入**的视觉模型可以**感知深度**。Keras中实现连体视觉模型（共享卷积基）如下cell\n",
    "~~~python\n",
    "y = model(x)\n",
    "y1, y2 = model([x1, x2])\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None,include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_input = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_input], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras回调函数和TensorBoard\n",
    "## 训练过程中将回调函数用于模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **模型检查点**：训练中保存模型\n",
    "* **提前终止**：如果随时不再改善，则中断训练\n",
    "* **训练过程中动态调节参数**：例如优化器的学习率\n",
    "* **记录训练指标和验证指标**：将模型表示可视化。keras进度条就是一个回调函数\n",
    "~~~python\n",
    "keras.callbacks.ModelCheckpoint\n",
    "keras.callbacks.EarlyStopping\n",
    "keras.callbacks.LearningRateScheduler\n",
    "keras.callbacks.ReduceLROnPlateau\n",
    "keras.callbacks.CSVLogger\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras                       # EarlyStopping 通常和 ModelCheckpoint 结合使用\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping( # 如果不再改善，则中段训练\n",
    "        monitor='acc',             # 监控指标为验证精度\n",
    "        patience=1,                # 在多余一轮的时间不再改善则中断训练\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint( # 每轮过后，保存模型权重\n",
    "        filepath='my_model.h5',      # 保存路径\n",
    "        monitor='val_loss',          # 监控指标\n",
    "        save_best_only=True,         # 如果 val_loss 没有改善则不覆盖文件\n",
    "    )\n",
    "    ...\n",
    "    keras.callbacks.ReduceLROnPlateau( # 降低学习率，回调函数\n",
    "        monitor='val_loss'             # 监控指标\n",
    "        factor=0.1,                    # 触发时将学习率除以10\n",
    "        patience=10,                   # 10轮内没有改善则触发\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.fit(x, y,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))# 要监控验证损失，记得传入验证数据validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **编写自己的回调函数**：创建`keras.callbacks.Callback`类的子类。实现下面这些方法：  \n",
    "  on_epoch_begin  &nbsp;&nbsp;每轮开始时被调用  \n",
    "  on_epoch_end   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每轮结束时被调用\n",
    "  \n",
    "  on_batch_begin  &nbsp;&nbsp;处理每个批次前被调用  \n",
    "  on_batch_end   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;处理每个批次后被调用  \n",
    "  \n",
    "  on_train_begin  &nbsp;&nbsp;训练开始时被调用  \n",
    "  on_train_end   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;训练结束时被调用  \n",
    "* **`logs`参数** ：是一个字典，里面包含前一个批量、前一个轮次、或前一个训练的信息。训练指标和验证指标等\n",
    "* **`self.model`** ：调用回调函数的模型实例\n",
    "* **`self.validation_data`** ：传入fit的验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'编写自己回调函数实例：每轮结束后，将模型的每层激活保存到硬盘，激活是对验证集的第一个样本计算得到'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'编写自己回调函数实例：每轮结束后，将模型的每层激活保存到硬盘，激活是对验证集的第一个样本计算得到'\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model  # 模型实例\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input,layer_outputs) # 新的模型实例\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "\n",
    "        validation_sample = self.validation_data[0][0:1] # 验证集的第一个sample\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w')\n",
    "        np.savez(f, activations)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TensorBoard` 是一个内置于TensorFlow中的基于浏览器的可视化工具。  \n",
    "**注意**:只有当keras使用tensorflow后端时，这一方法才能用于keras模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pengfeizhang\\Anaconda3\\envs\\learn36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras               # IMDB 文本分类，使用TensorBoard可视化\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "np.load = np_load_old\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128,input_length=max_len,name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model # pydot  pydot-ng  graphviz 库\n",
    "plot_model(model,show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pengfeizhang\\Anaconda3\\envs\\learn36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\pengfeizhang\\Anaconda3\\envs\\learn36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 5s 258us/step - loss: 0.6412 - acc: 0.6483 - val_loss: 0.4288 - val_acc: 0.8262\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 4s 190us/step - loss: 0.4514 - acc: 0.8214 - val_loss: 0.4549 - val_acc: 0.8092\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 4s 180us/step - loss: 0.3918 - acc: 0.8046 - val_loss: 0.9433 - val_acc: 0.6264\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80\n",
    "callbacks = [ \n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir=r'my_log_dir',  # TensorBoard 日志文件写入的位置\n",
    "        histogram_freq=1,         # 每一轮之后记录激活直方图\n",
    "        embeddings_freq=1,        # 每一轮之后记录嵌入数据 \n",
    "        #embeddings_data = np.arange(0, max_len).reshape((1, max_len)),\n",
    "        #embeddings_data = x_train[:100],\n",
    "        #embeddings_data = x_train,\n",
    "        #embeddings_data = np.arange(0, max_len).reshape((1, max_len)),\n",
    "        embeddings_data = x_train[:1],\n",
    "    )\n",
    "]\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=3,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 让模型性能发挥到极致\n",
    "让模型从“具有不错的性能”上升到“新能卓越且能够赢得机器学习竞赛”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高级架构模式\n",
    "\n",
    "### 批标准化\n",
    "* 三种重要的**设计模式**：残差连接；标准化；深度可分离卷积；\n",
    "* **标准化**：数据输入模型之前做标准化。假设数据服从正态分布（高斯分布），确保分布中心为0，同时缩放到方差为1\n",
    "* **批标准化**：即是在训练过程中，数据的均值和方差随时间变化，也可以适应性的将数据标准化，有助于梯度的传播。对于有些特别深的网络，只有包含多个`BatchNormalization`层时才能进行训练。例如keras中的许多高级CNN（ResNet50\\Inception V3\\Xception）\n",
    "* **`BatchNormalization`层通常在卷积层或密集连接层之后使用**  \n",
    "  conv_model.add(layers.Conv2D(32, 3, activation='relu'))  \n",
    "  conv_model.add(layers.BatchNormalization())  \n",
    "\n",
    "  dense_model.add(layers.Dense(32, activation='relu'))  \n",
    "  dense_model.add(layers.BatchNormalization())\t\t  \n",
    "* **`BatchNormalization`层接受一个参数axis**，表示对那个特征轴做标准化，默认是-1，即输入张量的最后一个轴。  \n",
    "  对于Dense，conv1D，RNN层，`data_famat`为`channels_last`的Conv2D层，默认值正确  \n",
    "  （`data_famat`为`channels_last`的Conv2D层，axis应设为1）  \n",
    "* ***批再标准化***：是对普通批标准化的最新改进\n",
    "* ***自标准化神经网络***：使用***特殊的激活函数（selu）和特殊的初始化器（lecun_normal）***，让数据通过任何Dnese层之后保持数据的标准化。这种方案虽然有趣，但目前仅限于密集连接网络，其有效性尚未得到大规模重复。\n",
    "### 深度可分离卷积\n",
    "* 可以代替Conv2D，让模型更轻量，任务性能更高\n",
    "* 深度可分离卷积：`SeparableConv2D`层；逐通道卷积+逐点卷积(**如下图：**)\n",
    "* 将空间特征学习，通道特征学习分开。**如果空间位置高度相关，不同通道相互独立。那么这样做很有意义**\n",
    "* 深度可分离卷积是Xception的基础\n",
    "![](https://dpzbhybb2pdcj.cloudfront.net/chollet/Figures/07fig16_alt.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model # 构建一个情况的深度可分离卷积，用于图像多分类任务（softmax）\n",
    "from keras import layers\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3,activation='relu',input_shape=(height, width, channels,)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数优化\n",
    "* 整天调节参数的工作，最好留个机器去做。\n",
    "* 制定一个原则，系统性的自动碳素可能的决策空间。\n",
    "* 可供选择的技术：贝叶斯优化、遗传算法、简单随机搜索\n",
    "* 挑战性：  \n",
    "  1、**计算反馈信号的代价可能很高**，它需要在数据及上创建一个新模型并从头开始训练  \n",
    "  2、**超参数空间由许多离散的决定组成，既不是连续的，也不是可微的。**通常不能再超参数空间使用梯度方法。  \n",
    "* 方法：  \n",
    "  1、通常情况下，**随机搜索**（随机选择需要评估的超参数，并重复这一过程）就是最好的方案，也是最简单的方案。  \n",
    "  2、**`Hyperopt`**是一个用于超参数优化的Python库，其内部使用`Parzen`估计器的树来预测那组超参数可能会得到很好的效果。另一个叫做**`Hyperas`的库将`Hyperopt`与`Keras`模型结合在一起**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本章总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn36]",
   "language": "python",
   "name": "conda-env-learn36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
